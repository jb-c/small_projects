{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import errno\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_to_get = \"part_A\" # Needs to be a valid key for the div_ids dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://courses.maths.ox.ac.uk/overview/undergraduate\" # Course page home url\n",
    "div_ids = {\"part_A\":\"50879\",\"part_A_Maths_and_Phi\":\"50805\",\"part_B\":\"49210\",\"part_C\":\"49743\",\"MMath_phis\":\"44954\"}\n",
    "\n",
    "root_url = \"https://courses.maths.ox.ac.uk\" \n",
    "\n",
    "output_dir = f\"P:/Desktop/maths/{course_to_get}\" # Directory where you want all the files to be dumped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url)\n",
    "soup= BeautifulSoup(response.text, \"html.parser\")\n",
    "course_page = soup.find(id=div_ids[course_to_get]) # The container for all the links, this is the same for part A,B,C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's likely that  <a href=\"https://courses.maths.ox.ac.uk/sites/default/files/Guide%20to%20Part%20A%20Courses_0.pdf\">Guide to Part A courses</a>  isn't a link to a course page\n"
     ]
    }
   ],
   "source": [
    "files = {} # Dict to store (module name,file list) pairs\n",
    "\n",
    "for course_link in course_page.select(\"a\"):    \n",
    "    \n",
    "    try:\n",
    "        materials_resp = requests.get(root_url + course_link[\"href\"]+\"/materials\")\n",
    "        matertials_soup = BeautifulSoup(materials_resp.text, \"html.parser\")\n",
    "        \n",
    "        course_name = course_link.text\n",
    "        public_files = matertials_soup.find(\"table\")\n",
    "        \n",
    "        course_files = [] # Array of (link,name) tuples\n",
    "        for file_link in public_files.findAll(\"a\"):\n",
    "            if(file_link[\"href\"].startswith(\"/node/view_material\")):\n",
    "                course_files.append((root_url+file_link[\"href\"],file_link.text))\n",
    "        files[course_name]=course_files\n",
    "    except:\n",
    "        print(\"It's likely that \",course_link,\" isn't a link to a course page\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Save Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We parse the files after we have finished scraping all content links\n",
    "\n",
    "for course in files:\n",
    "    course_files = files[course]\n",
    "    \n",
    "    if(len(course_files)>0):\n",
    "        for url,name in course_files:\n",
    "            try:\n",
    "                file_path = output_dir + f'/{course.replace(\":\",\"-\")}/{name.replace(\":\",\"-\")}.pdf' \n",
    "                file_content = requests.get(url).content\n",
    "            \n",
    "\n",
    "                if not os.path.exists(os.path.dirname(file_path)):\n",
    "                    try:\n",
    "                        os.makedirs(os.path.dirname(file_path))\n",
    "                    except OSError as exc: # Guard against race condition\n",
    "                        if exc.errno != errno.EEXIST:\n",
    "                            raise\n",
    "\n",
    "                with open(file_path, \"wb\") as f:\n",
    "                    f.write(file_content)\n",
    "            except:\n",
    "                print(f'There was an issue getting {name} from {course}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
